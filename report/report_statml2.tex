\documentclass[a4paper,10pt]{article}
\usepackage{a4wide}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{xfrac} 				% gives \sfrac
\usepackage{amsmath}
\usepackage{enumerate} 		% allows you to change counters
\usepackage{verbatim}
\usepackage{comment}				% gives comment environment
\usepackage{hyperref}
\usepackage{amssymb}				% gives f.x. \mathbb{R}

% graphics packages
\usepackage{graphicx}
\usepackage{caption} 	
\usepackage{subcaption}
\usepackage{float}

\title{
	Assignment 2 - Basic Learning Algorithms	\\
	Statistical Methods for Machine Learning
  }
\author{
	Guðmundur Páll Kjartansson \\
	Jón Gísli Egilsson
}

% Uncomment to set paragraph indentation to 0 points, and skips a line
% after an ended paragraph.
\setlength{\parindent}{0pt}
\setlength{\parskip}{\baselineskip}

\begin{document}
\maketitle

\section*{II.1 Regression}

\subsection*{II.1.1 Maximum likelihood solution}

The models for variable selections $1$ and $2$ are implemented in the file \verb=regression.py=. We then applied both models to the test set and computed the RMS averaged over $100$ different selections of training and test data (where the training data was always $80\%$ and test data $20\%$ of the data in the file \verb=bodyfat.txt=). Our measured RMS errors for selection $1$ and $2$ respectively were
$$\text{RMS}_1 \approx 4.5$$
and
$$\text{RMS}_2 \approx 5.$$

\subsection*{II.1.2 Maximum a posteriori solution}

We also implemented the MAP estimate in \verb=regression.py=. In figure $1$ we can see the RMS error for the MAP estimate plotted for different values of the precision parameter $\alpha$. The RMS for the maximum likelihood solution was included in the plot for the same dataset for comparison.

Comparing the selections we see that selection $1$ seems to provide better prediction than selection $2$ given the minimizing $\alpha$ value. And if we chose $\alpha$ to be anywhere between $0$ and $0.1$ (not including $0$) we will get better results with the MAP estimate than the ML one. Similarly if we have $0 < \alpha \leq 0.24$ for selection $2$ the MAP provides better prediction than the ML one.

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
  		\centering
  		\includegraphics[width=\textwidth]{../images/rms_selection1.png}
  		\caption{Selection $1$}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
  		\centering
  		\includegraphics[width=\textwidth]{../images/rms_selection2.png}
  		\caption{Selection $2$}
  \end{subfigure}
  	\caption{RMS for MAP and ML}
\end{figure}

\section*{II.2 Classification}

\subsection*{II.2.1 Linear discriminant analysis}

We implemented the linear discriminant analysis algorithm in \verb=classification.py=. In figure $2$ we can see the three different classes in the training data.
\begin{figure}[H]
	\centering
  		\centering
  		\includegraphics[width=0.6\textwidth]{../images/iris_scatter.png}
  		\caption{Scatter plot of Iris data}
\end{figure}
Now to quantify the error of the LDA we compute the probability of misclassification for the training and test data respectively. The errors are
$$\epsilon_{\text{training}} = 0.21$$
and
$$\epsilon_{\text{test}} = 0.18$$

\begin{comment}
\begin{figure}[H]
	\centering
	\begin{subfigure}{0.45\textwidth}
  		\centering
  		\includegraphics[width=\textwidth]{../week4/images/prob41asurf.png}
  		\caption{$x=(0,-1)$}
  \end{subfigure}
  \begin{subfigure}{0.45\textwidth}
  		\centering
  		\includegraphics[width=\textwidth]{../week4/images/prob41bsurf.png}
  		\caption{$x=(0,0.05)$}
  \end{subfigure}
  	\caption{Surface plots of $m(p)$ at different points}
\end{figure}
\end{comment}


\end{document}




































